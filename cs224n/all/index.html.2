<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
         "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Christopher Manning, Stanford NLP</title>
<link href="simple-styles.css" rel="stylesheet" title="dissertations_style" type="text/css">
<!-- <link href="fsnlp.css" rel="stylesheet" title="fsnlp_style" type="text/css"> -->
<link rel="canonical" href="https://nlp.stanford.edu/~manning/">
<meta name="description" content="Christopher Manning, Professor of Computer Science and Linguistics, Stanford University">
<meta name="keywords" content="Christopher D. Manning, Chris Manning">
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
<a href="images/Christopher_Manning_027_1154x1154.jpg"><img src="images/Christopher_Manning_027_132x132.jpg" align="right"
 width="132" height="132" alt="" border="0"></a>
<h1>Christopher Manning</h1>
<h3>Thomas M. Siebel Professor in Machine Learning, Professor of Linguistics and of Computer Science<br>
<!-- <h4>Sony Faculty Scholar in the School of Engineering</h4> -->
Director, Stanford Artificial Intelligence Laboratory (SAIL)<br>
Associate Director, Stanford Institute for Human-Centered Artificial Intelligence (HAI)</h3>
<h4><a href="https://nlp.stanford.edu/">Stanford NLP Group</a>,
<a href="https://ai.stanford.edu/">Stanford AI Lab</a>,
<a href="https://hai.stanford.edu/">HAI</a>,
<a href="https://linguistics.stanford.edu/">Linguistics</a> and 
<a href="https://www.cs.stanford.edu/">Computer Science</a>,
<a href="https://www.stanford.edu">Stanford University</a>
</h4>

<h2>What's New?</h2>

<ul>
<li><a href="https://arxiv.org/abs/2305.18290">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a> (<a href="https://github.com/eric-mitchell/direct-preference-optimization">github</a>) was one of <a href="https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/">the two Outstanding Main Track Runner-Ups at NeurIPS 2023 (2023)</a>.
<li>The Stanford Chirpy Cardinal team, advised by Chris Manning, <a href="https://www.amazon.science/alexa-prize/socialbot-grand-challenge/2022">won first place in the scientific innovation category in the Alexa Prize SocialBot Grand Challenge 5</a> (2023).
<li>‚Äú<a href="https://aclanthology.org/2023.acl-long.506/">Backpack Language Models</a>‚Äù, by John Hewitt, John Thickstun, Christopher Manning, and Percy Liang, received received an <a href="https://2023.aclweb.org/program/best_papers/">Outstanding Paper Award</a> at ACL 2023.
<li>Our paper ‚Äú<a href="https://aclanthology.org/D13-1170/">Recursive Deep Models for Semantic Compositionality over a Sentiment Treebank</a>‚Äù won a <a href="https://www.aclweb.org/portal/content/announcement-2023-acl-test-time-paper-award">Test-of-Time Paper Award</a> at ACL 2023. 
<li>I worked hard on collecting footage and organizing the timeline and details for the short video <a href="https://www.youtube.com/watch?v=Cn6nmWlu1EA">AI at Stanford: 1962‚Äì2022</a>. It received <a href="images/IMG_8909.jpg">a Northern California Emmy Award</a>! (2023)</li>
<li>Our work on <a href="https://detectgpt.ericmitchell.ai/">DetectGPT</a>, which uses a new ‚Äúlikelihood curvature‚Äù idea for detecting LLM output, at ICML 2023, has been covered in <a href="https://www.science.org/content/article/scientists-explore-ai-written-text-journals-hammer-policies">Science</a> and <a href="https://www.ft.com/content/e34c24f6-1159-4b88-8d92-a4bda685a73c">The Financial Times</a> (2023)</li>
<li><a href="images/IMG_2101-Chris-doctorate-Amsterdam.jpg">I received an honorary doctorate from the University of Amsterdam</a> (2023)</li>
</ul>

<h2>Bio</h2>

<p>
Christopher Manning is the inaugural Thomas M. Siebel Professor in Machine Learning in the
Departments of Linguistics and Computer Science at Stanford University, 
Director of the Stanford Artificial Intelligence Laboratory (SAIL), 
and an Associate Director of the Stanford Institute for Human-Centered Artificial Intelligence (HAI). 
His research goal is computers that can intelligently process, understand, and generate human languages. 
Manning was an early leader in applying Deep Learning to Natural Language Processing (NLP), with well-known research on the GloVe model of word vectors, attention, machine translation, question answering, self-supervised model pre-training, tree-recursive neural networks, machine reasoning, dependency parsing, sentiment analysis, and summarization.
He also focuses on computational linguistic approaches to parsing, natural language inference and multilingual language processing, including being a principal developer of Stanford Dependencies and <a href="https://universaldependencies.org/">Universal Dependencies</a>.
Manning has coauthored leading textbooks on statistical approaches to NLP (Manning and Sch√ºtze 1999) and information retrieval (Manning, Raghavan, and Sch√ºtze, 2008), as well as linguistic monographs on ergativity and complex predicates. His online CS224N Natural Language Processing with Deep Learning videos have been watched by hundreds of thousands of people.
He is an ACM Fellow, a AAAI Fellow, and an ACL Fellow, and a Past President of the ACL (2015).
His research has won ACL, Coling, EMNLP, and CHI Best Paper Awards, and an ACL Test of Time Award.
He has a B.A. (Hons) from The Australian National University and a Ph.D. from Stanford in 1994, and an Honorary Doctorate from U. Amsterdam in 2023, and he held faculty positions at Carnegie Mellon University and the University of Sydney before returning to Stanford. He is the founder of the <a href="/">Stanford NLP group</a> (<a href="https://twitter.com/stanfordnlp">@stanfordnlp</a>) and manages development of the <a href="https://stanfordnlp.github.io/CoreNLP/">Stanford CoreNLP</a> and <a href="https://stanfordnlp.github.io/stanza/">Stanza</a> software.
</p>
<!-- other Thomas M. Siebel Profesors: Tommi Jaakkola at MIT, Michael J. Franklin at Berkeley, and 2 people, one in CS at UIUC. -->

<h2>Contact</h2>

<!-- <table border="0" align="center" bgcolor='#80c080'> FCD0DC is okay pink -->
<table border="0" align="center" bgcolor="F0F0F0">
  <tr valign="top">
    <td style="width:10%"><b>M</b></td>
    <td>
Dept of Computer Science, Gates Building 3A,
353 Jane Stanford Way,
Stanford CA 94305-9030,
USA
     </td>
  </tr>
  <tr>
    <td><b>E</b></td>
    <td><a href="mailto:manning@cs.stanford.edu">manning@cs.stanford.edu</a></td>
  </tr>
  <tr>
    <td><b>T</b></td>
    <td><a href="https://twitter.com/chrmanning">@chrmanning</a></td>
  </tr>
  <tr>
    <td><b>W</b></td>
    <td>+1 (650) 723-7683</td>
  </tr>
  <tr>
    <td><b>F</b></td>
    <td>+1 (650) 725-1449</td>
  </tr>
  <tr>
    <td><b>R</b></td>
    <td>Gates 348</td>
  </tr>
  <tr>
    <td><b>O</b></td>
    <td>For CS224N: Mon 2:45‚Äì5:00pm, book <a href="https://calendly.com/manning/cs224n-office-hours">here</a>;
    otherwise contact Suzanne</td>
  </tr>
  <tr valign="top">
    <td><b>A</b></td>
    <td>Suzanne Lessard, Gates 232, +1 (650) 723-6319
    <a href="mailto:slessard@stanford.edu">slessard@stanford.edu</a>
    </td>
  </tr>
</table>

<h2>Brief CV</h2>

<ul>
  <li>I'm Australian üá¶üá∫ (‚ÄúI come from a land of wide open spaces ‚Ä¶‚Äù)
  <li>BA (Hons) Australian National University 1989 (majors in mathematics,
computer science and linguistics)
  <li>PhD Stanford Linguistics 1994
  <li>Asst Professor, Carnegie Mellon University Computational Linguistics
Program 1994‚Äì96
  <li>Lecturer B, University of Sydney Dept of Linguistics 1996‚Äì99
  <li>Asst Professor, Stanford University Depts of Computer Science and
Linguistics 1999‚Äì2006
  <li>Assoc Professor, Stanford University Depts of Linguistics and
  Computer Science 2006‚Äì2012
  <li>Professor, Stanford University Depts of Linguistics and
  Computer Science 2012‚Äì
  <li>President of the Association for Computational Linguistics 2015
  <li>Thomas M. Siebel Professor in Machine Learning, Professor of Linguistics and of Computer Science 2017‚Äì
  <li>Honorary Doctorate, University of Amsterdam 2023
</ul>

<h2>Papers</h2>

<p>
Here is <a href="papers/">my publications list</a>.
However, I've become lazy, so you're more likely to find recent stuff on the
<a href="http://nlp.stanford.edu/pubs/">NLP Group publications page</a>, 
<a href="http://scholar.google.com/citations?user=1zmDOdwAAAAJ">Google Scholar</a>, or
<a href="https://www.semanticscholar.org/author/Christopher-D.-Manning/144783904">Semantic Scholar</a>.
</p>

<h2>Books</h2>

<p>
<a href="http://informationretrieval.org/">Introduction
to Information Retrieval</a>, with Hinrich Sch&uuml;tze and Prabhakar
Raghavan (Cambridge University Press, 2008).  Manning and
Sch&uuml;tze, <a href="/fsnlp/promo/">Foundations
of Statistical Natural Language Processing</a> (MIT Press, 1999).
Andrews and Manning, <a href="http://www.amazon.com/exec/obidos/ASIN/157586164X/">Complex
Predicates and Information Spreading in LFG</a> (1999).
<a href="http://www.amazon.com/exec/obidos/ASIN/1575860368/">Ergativity:
Argument Structure and Grammatical Relations</a> (1996).
</p>

<h2>Conferences and Talks</h2>

<p>
Some of my <a href="talks/">talks</a> are available online.
</p>

<p>
In 2013, I was program co-chair for the first
<a href="http://www.iclr.cc/">International
Conference on Learning Representations</a> (see: <a href="https://sites.google.com/site/representationlearning2013/">ICLR 2013</a>).
The 2013 edition was a really 
fun workshop-scale event.  Since then, ICLR has grown in size exponentially.
</p>

<p>
In 2013, I helped organize the first
<a href="https://sites.google.com/site/cvscworkshop/">CVSC
  workshop</a>.  It was a really
lively workshop.  I also helped organize
<a href="https://sites.google.com/site/cvscworkshop2014/">a second
  Workshop on Continuous Vector Space Models and their
  Compositionality</a> at EACL 2014.
I helped organize a 
<a href="http://nlp.stanford.edu/events/illvi2014/">Workshop on
Interactive Language Learning, Visualization, and Interfaces</a>
to be held at <a href="http://acl2014.org/">ACL 2014</a>, trying to
build an interdisciplinary community interested in the intersection of
NLP, HCI, and data visualization.
</p>


<h2>Students</h2>

<p>
I have a page listing all my <a href="dissertations/">Ph.D. graduates</a>. 
You can find all my current students on the <a href="http://nlp.stanford.edu/people/">Stanford NLP Group People</a> page.
</p>

<h2>Research Projects</h2>

<p>
The general area of my research is robust but linguistically sophisticated
natural language understanding and generation, and opportunities to use it
in real-world domains.  
Particular current topics include deep learning for NLP, compositionality, question answering, 
large pre-trained language models, knowledge and reasoning, 
Universal Dependencies, and low-resource languages. To find out more about what I do, it's
best to look at my <a href="papers/">papers</a>.
</p>

<!--
<p>My research at Stanford is currently supported by 
the NSF, DARPA, Bloomberg, Tencent, UST Global.
-->
<!-- an IBM Faculty Partnership Award, IARPA, -->
<!--
Previous funding at Stanford comes from IARPA/DTO
 a Terman Fellowship, <a
href="http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=0085896">NSF</a>
(for <a href="http://i.stanford.edu/gib/">GIB</a>), NTT, NHK, and the
Australian Reseach Council.  -->
<!-- </p>  -->

<ul>
<li>Unadmitted students: I don't do admissions. You need to apply to a program in the usual
manner; see the pages for  
<a href="https://linguistics.stanford.edu/degree-programs/graduate-admissions">https://linguistics.stanford.edu/degree-programs/graduate-admissions</a>,
and for <a href="https://cs.stanford.edu/Admissions/">Computer Science</a>.
</li> 
<li>PhD students in CS/Linguistics or allied fields: please contact me
directly about research opportunities.</li>
<li>Masters students: I often employ a couple of masters
	  students.  Most appealing are people with a background in NLP,
	  and time to devote to an RAship. It helps your case to have done well
  in <a href="http://cs224n.stanford.edu">CS 224N: NLP</a>.</li>
<li>Undergraduate students in CS/Linguistics or allied fields: please
contact me directly.</li>
</ul>


<h2>Courses</h2>

<p><b>Online videos!</b> You can find complete videos for several NLP  courses that I have (co-)taught online:
</p>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4">CS224N: Natural Language Processing with Deep Learning</a> is available on YouTube, with <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/index.html#schedule">accompanying slides</a>. There have been four editions so far: (i) 2017 <a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6">playlist</a> and <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/syllabus.html">slides</a>, (ii) 2019 <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z">playlist</a> and <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/index.html#schedule">slides</a>, (iii) 2021 <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ">playlist</a> and <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/index.html#schedule">slides</a>, (iv) 2023 update <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4">playlist</a> and <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1234/index.html#schedule">slides</a>..

<li><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ&amp;disable_polymer=true">Natural Language Processing</a> (a.k.a. the 2012 Coursera NLP-class, one of the earliest MOOCs) by <a href="http://web.stanford.edu/~jurafsky/">Dan Jurafsky</a> and Christopher Manning on YouTube [<a href="http://web.stanford.edu/~jurafsky/NLPCourseraSlides.html">slides</a>]. If you don't have much background in AI, ML, or NLP, you should start with this class. A more modern take on a broader range of content appears in <a href="https://www.youtube.com/channel/UC_48v322owNVtORXuMeRmpA/videos">CS124/Linguist 180: From Languages to Information</a> [<a href="http://web.stanford.edu/class/cs124/">slides</a>], primarily by Dan Jurafsky, but I still make some cameo appearances for Information Retrieval. We haven't found the energy to keep doing this class.</li>
<li><a href="https://see.stanford.edu/Course/CS224N">Natural Language Processing</a> (a.k.a. CS224N Spring 2008) by Christopher Manning [<a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1086/">slides</a>]. This is an aging version of my traditional probabilistic NLP course. It looks like you can only watch these videos with Flash. ‚òπÔ∏è </li>
</ul>

<p>In Autum 2022, I taught <a href="https://web.stanford.edu/class/linguist200/">Linguistics
200: Foundations of Linguistic Theory</a>. This is a class for Linguistics Ph.D. students, aimed at giving them a richer, broad appreciation of the development of linguistic thinking.</p>

<p>
Nearly every year since 2000, I teach
<a href="http://web.stanford.edu/class/cs224n/">CS 224N / Ling 284. Natural
	Language Processing with Deep Learning</a>
<!-- Many <a href="http://nlp.stanford.edu/courses/cs224n/">previous student projects</a> are available online. -->
</p>

<p>In Fall 2016, I taught <a href="https://web.stanford.edu/class/archive/linguist/linguist278/linguist278.1172/">Linguistics
278: Programming for linguists</a> (and any other digital humanities or
text-oriented social science students who think it might be a good
match), mainly using Jupyter notebooks.</p>

<p>
From 2003 through 2019, I taught
<a href="http://web.stanford.edu/class/cs276/">CS 276: Information
Retrieval and Web Search</a>, in recent years with
<a href="https://www.pandunayak.com/">Pandu Nayak</a>.
Earlier versions of this course include two years of two-quarter sequences
CS276A/B on information retrieval and text information classification
and extraction, broadly construed ("IR++"):
<a href="http://web.stanford.edu/class/cs276a/">Fall
quarter course website</a>, 
<a href="http://web.stanford.edu/class/cs276b/">Winter
quarter course website</a>.
Early versions of this course were co-taught by
me, <a href="https://theory.stanford.edu/~pragh/">Prabhakar Raghavan</a>,
and <a href="https://www.cis.uni-muenchen.de/schuetze/">Hinrich Sch&uuml;tze</a>.
</p>

<p>I co-taught tutorials on 
<a href="http://nlp.stanford.edu/courses/NAACL2013/">Deep Learning for NLP</a> at 
ACL 2012 with Yoshua Bengio and Richard Socher, and at
NAACL 2013 with Richard Socher. Slides, references, and videos are
available.
</p>

<p>In June 2011, I taught a tutorial
<a href="/~manning/courses/DigitalHumanities/">Natural Language
  Processing Tools for the Digital Humanities</a> at
 <a href="https://dh2011.stanford.edu/"><i>Digital Humanities 2011</i></a>
at Stanford. 
</p>

<p>
In fall 2007 I taught
<a href="courses/ling289/ling289-2007-syllabus.htm">Ling 289:
Quantitative and Probabilistic Explanation in Linguistics</a>
MW 2:15-3:45 in 160-318.
I previously taught it in winter 2002 
(n&eacute;e <a href="courses/ling236/">Ling 236</a>) and
Winter 2005 (as <a href="courses/ling235/">Ling 235</a>).
</p>

<p>In the summer of 2007, I taught at the LSA Linguistic Institute:
<a href="http://nlp.stanford.edu/courses/lsa354/">Statistical
Parsing</a> and 
<a href="http://nlp.stanford.edu/courses/lsa306/">Computational
Linguistics in Industry</a>.</p>

<p>
In fall 1999 and winter 2001, I taught
<a href="http://web.stanford.edu/class/cs121/">CS 121 Artificial 
Intelligence</a>.  The text book was S. Russell and P. Norvig,
<a href="http://aima.cs.berkeley.edu/">Artificial
Intelligence: A Modern Approach</a>.
</p>

<p>
I ran the NLP Reading Group from 1999-2002. 
<a href="http://nlp.stanford.edu/read/">The NLP Reading Group</a> is now student organized.
</p>

<h2>Other stuff</h2>

<!--
<p>
With mobile email, I desperately needed spam filtering happening
on the mail server.  Here are <a
href="mobile/IMAPfiltering.html">instructions</a> on how to set that up
at Stanford.  For using the web, here are some 
some <a href="mobile/">sites for PDA browsing</a>.</p>
-->

<p>
LaTeX: When I used to have more time (i.e., when I was a grad student), I used
to spend some of it writing <a href="tex/">(La)TeX macros</a>.
[Actually, that's a lie; I still spend some time doing it....]
</p>


<p>
We've got two kids: Joel [<a href="https://www.linkedin.com/in/joel-manning-375b88127/">linkedin</a>, <a href="https://github.com/bokken12">github</a>] and Casey [<a href="https://www.linkedin.com/in/caseytmanning/">linkedin</a>, <a href="https://github.com/CaseyManning">github</a>].  Here are my (aging) opinions on 
<a href="kids-books-0-3.html">books for kids</a>.
</p>

<!--
<p>
Me in the <i>Stanford Report</i>: <a
href="http://www.stanford.edu/dept/news/report/news/october13/presreport-1013.html">appointment</a>,
<a href="http://www.stanford.edu/dept/news/report/news/october20/terman-1020.html">Terman</a>,
<a href="http://www.stanford.edu/dept/news/report/news/december1/csli-121.html">csli</a>, 
<a href="http://www.stanford.edu/dept/news/report/news/april19/oed-419.html">lexicography</a>, 
<a href="http://www.stanford.edu/dept/news/report/news/may10/database-510.html">database</a>,
<a href="http://www.stanford.edu/dept/news/report/news/september20/ITRawards-920.html">itr 2000</a>,
<a
href="http://www.stanford.edu/dept/news/report/news/february28/aaasmanning-221.html">AAAS 
2001</a>,
<a href="http://news-service.stanford.edu/news/april3/inprint-43.html">on
NewsBlaster</a>,
<a href="http://news-service.stanford.edu/news/october31/minutes-1031.html">childcare</a>,
<a href="http://news-service.stanford.edu/news/2003/may21/google-521.html">PageRank
speed-ups</a>,
<a href="http://news-service.stanford.edu/news/2003/october22/prezreport-1022.html">reappointment</a>.
</p>
-->

<hr>
<code>http://nlp.stanford.edu/~manning/</code><br>
<address>
Christopher Manning 
<a href="mailto:manning@cs.stanford.edu">&lt;manning@cs.stanford.edu&gt;</a>.
<!-- hhmts start -->
Hand-rolled HTML. Last modified: 2023-03-05.
<!-- hhmts end -->
</address>
<!-- I come from a land of wide open spaces
Where the world turns around us and we just follow suit
There's heat in the air and peace reigns supreme
Got white flags on the clothes lines and the deals are new -->
</body>
</html>
